{"/about":{"title":"About","data":{"":"This is the about page! This page is shown on the navbar."}},"/case-study/contract_testing":{"title":"Contract Testing","data":{"":"Many of the benefits of integration and E2E tests can also be achieved using contract tests. Furthermore, contract tests attempt to maintain independent service development cycles, while also provided faster feedback loops than broadly-scoped tests can typically attain.The typical way to integration test two services is to spin up both services in the same environment, and cause the consumer service to make API calls to the provider service. If the provider service responds correctly, and the consumer service handles the responses correctly, the integration tests are successful.(diagram here illustrating an integration test)During contract tests, the interactions between the consumer and provider services are described in a document called a contract. Both services can be individually tested to determine if they conform to the contract. If either service does not behave according to what is described in the contract, the test fails, and the team which owns the service is notified that their service will not integrate correctly with the other service.(diagram here illustrating a contract test)","benefits-of-contract-testing#Benefits of Contract Testing":"Contract testing aims to maintain the independent deployability of each service. It allows a team to test that their service performs its side of an integration correctly, without the need to spin up the other service.Not only do contract tests decouple the development life-cycles of different teams, but they also provide much faster feedback than integration and E2E tests. Contract tests behave more like unit test or service tests, and can be run quickly, cheaply, and early on in the CI/CD pipeline. They are lightweight enough that a developer could even run them locally before initiating the build processes. (much of the content of this paragraph is duplicated above...)Another benefit of contract tests is that they provide more fine-grained feedback than most integraion and E2E tests. Becuase each interaction in the contract is tested individually, when a contract test fails, the devoloper is informed of exactly which request or response was missing or malformed. (We don't focus on this as a problem in the background section... maybe add it?)","weaknesses-of-contract-testing#Weaknesses of Contract Testing":"While contract tests reduce the need for broadly-scoped tests, they do not replace them entirely. Integration and E2E test provide a lot of confidence because they try to re-create production conditions as accurately as possible. Contract tests are not designed to replicate conditions like latency, service unavailability, and high amounts of load. Ideally, contract tests can reduce the dependence on E2E tests enough that they can be run asynchronously from the CI/CD pipeline. Successful implementation of contract testing increases the independence of teams, while still maintaining a high degree of confidence that breaking changes will be caught early on.Another trade-off with contract testing is that it usually requires a large startup cost at the beginning. Some forms of contract testing require swaths of new unit tests to be written. In these cases, an organization does not get the confidence benefit of contract testing until the new unit tests cover the majority of the service's interface.","evaluating-various-forms-of-contract-testing#Evaluating various forms of Contract Testing":"There are many approaches to contract testing, and each vendor has a slightly different take on how it should be conducted. The different methodologies can generally be classified according to how they answer two questions:\nDoes the contract test care about schema or sementics?\nWhat is the ultimate source of truth that defines what the integration should look like?\n(who gets to decided what is in the contract? how is the contract generated?)","schema-vs-semantics#Schema vs. Semantics":"Contract tests are intended to catch inintended changes to the integration that will cause the consumer service to break. The breaking change can occur in either the consumer or the provider service. Contract tests can be categorized according to the type of breaking change they screen for:\nSchema change - a change to the structure of a message\nSemantic change - a change to the meaning of a message\n\n(I think it is probably worth cutting the section below... or at least having a more concise example)\nSuppose we have a consumer service that wants to know the Date of Birth for a specific user. The service uses HTTP, and makes a request to the \"Users\" microservice that looks like this:\nGET /users/date-of-birth?username=catowner22\nThe consumer service is expecting the \"Users\" service to respond with a payload like this:\n{\n\"username\": \"catowner22\",\n\"dob\": \"7-10-1998\"\n}\nInstead of giving the DOB as a string, what if the provider returns a number instead--the date in  milliseconds since the UNIX epoch:\n{\n\"username\": \"catowner22\",\n\"dob\": 900028800000\n}\nThis is a schema change--the meaning of the value is the same, but its format is different.Instead, what if the \"Users\" service response with a different date?\n{\n\"username\": \"catowner22\",\n\"dob\": \"1-23-2005\"\n}\nThis constitutes a semantic change--the value has the same format, but the meaning of the value is different.Some styles of contract testing are purely schema-based. They don't check what the values in a message are, they only check that the structure of the message is correct. Contract tests that also verify the semantics provide more confidence. They are able to catch more breaking changes than purely schema based tests. The drawback to semantic tests is that they often require significant work to implement. Contract testing methodologies that require writing a bunch of new tests are usually the ones that care about message semantics, which is why the tests cannot be easily automated.","the-source-of-truth#The source of truth":"The other key differentiator between methodologies is how they determine the ultimate source of truth. When a contract test fails, how do we know what the integration should actually look like? Existing solutions generally fall into one of three categories (some vendors offer multiple products that belong to different buckets):\nConsumer-driven - the consumer service is the source of truth\nProvider-driven - the provider service is the source of truth\nSpec-driven - the source of truth is seperate from either service's implementation","consumer-driven#Consumer-driven":"In consumer-driven contract testing, the consumer service is implemented first. After the consumer team has implemented their side of the integration, they use unit tests to generate a consumer contract, which describes the expectations that the consumer service has of the provider service. The consumer contract is handed over to the provider team, and they implement the provider service's interface to satisfy the needs of the consumer.One advantage of a consumer-driven approach is that the contract only includes the parts of the provider's API which are actually being used. This gives the provider team insight into how they can evolve their API without breaking the consumers.Another benefit of consumer-driven contracts is they typically describe the semantic details. The actual requests the consumer makes and the responses the consumer expects are recorded in the contract. When the provider is verified against the contract, the requests are replayed against the provider service. As far as contract tests go, this methodology yields the most confidence that the services integrate correctly.Although a consumer-driven approach has clear benefits, it also comes with significant trade-offs. Perhaps the biggest one is that it undermines independent deployability for consumer services. When a consumer service is updated, a new consumer contract is generated. Before the consumer service can be deployed, the consumer contract must be pulled down by the provider team, the provider service must be spun up, and the interactions in the contract must be repayed against the provider. After that, the results of the test must be sent back over to the consumer team. Only when the consumer team is notified of a successful test are they able to proceed to deploying the new version of the consumer. In the event that provider verification fails, either the consumer team must fix the issue and start the process over again, or they must wait for the provider team to update their API to satisfy the contract.In either case, the consumer team does not get immediate feedback about whether their service is compatible with the provider. The provider team has to be involved. Taking into account that microservices often have multiple external dependencies, performing consumer-driven contract testing requires coordination from multiple teams any time a service is updated.(Two more drawbacks that are not mentioned for brevity):\n(-) workflow is unintuitive, and does not align with how most teams agree on APIs\n(-) consumer must be implemented first","provider-driven#Provider-driven":"Provider-driven contract testing is nearly the reverse of consumer-driven. The provider service is implemented first, and a provider contract is generated that describes the provider's side of the integration. Usually the provider contract comes in the form of an API specification, other times the provider team distributes a test-double which consumers can test against.The main benefit of a provider-driven approach is that it gives the provider team authority over what the integration must look like. Whether or not this is a good fit is specific to the organization, and depends on the roles of the services involved. Many organizations prefer a more collaberative approach to API design, where consumer and provider teams work together.Provider-driven contract tests are mainly schema-based, unless significant effort is expended to tailor the contract (or test double) to all of the consumers involved. It is natural to describe an API in terms of the schema is requires and the general behaviors it is capable of. However, it is difficult-to-impossible to exhaustively describe the semantics of every possible interaction with the API. Creating specific test cases requires knowledge of a given consumers needs, and a provider contract is not a natural fit for that purpose.","spec-driven#Spec-driven":"Spec-driven contract testing (a.k.a. \"contract-driven\" or \"law-driven\") occurs when the API spec is defined independently of either service's implementation. Usually this means that the API spec is agreed upon by both teams, and then both of them are individually responsible for correctly implementing what was agreed upon.This approach flows naturally out of Spec-first API design, a practice where the provider team decides on a spec before writing the code, instead of documenting their implementation after it is completed. This design philosophy is beneficial becuase it allows both the consumer and provider services to be implemented simultaneously. As each service finishes implemenation, it can be independently tested against the API spec to verify that it will integrate correctly with the other service.Spec-driven contract testing is the most conducive to independent deployability. The API spec is decided at the beginning, and both services can be tested against the spec independently. Neither team needs help from the other to test the integration. As long as the both teams require every new version of their service to be tested for conformance to the spec, the life-cycles of the two services remain decoupled.","existing-solutions#Existing Solutions":"Should we only focus on spec-driven ones?"}},"/case-study/design_decisions/central_document_repository":{"title":"Central Document Repository","data":{"":"","single-source-of-truth#Single Source of Truth":"A crucial characteristic of Deploy Guard is its global consistency, ensuring that running Deploy Guard for the consumer team yields the same results as if the provider team were running it.\nWithout global consistency, teams must face the challenge of resolving conflicts in Deploy Guard results.\nDeploy Guard's results depend on the definitions of both the consumer contract and the provider specification.\nConsequently, global consistency can only be achieved if Deploy Guard reads the documents from a central repository.\nReading documents from individual repositories of the consumer and provider teams introduces the risk of unsynchronized documents, leading to conflicting results in Deploy Guard.\nWhile Github can serve as a central repository, we decided that developing a dedicated broker would be a more suitable approach as it allows us to provide features specific to contract testing. We'll discuss the tradeoffs of this decision in the following sections.","the-positives#The Positives":"","encapsulating-logic#Encapsulating Logic":"With a dedicated broker, Signet's functionality is no longer confined within the Signet CLI.\nInstead, the broker handles various tasks, including the logic for Deploy Guard.\nThis enables automatic fetching of data for documents and deployment states of consumer and provider versions.\nIf Github were the central repository, implementing automatic fetching would be challenging, and developers would have to manually provide Deploy Guard with data about documents and deployment states.","automatic-comparison#Automatic Comparison":"The Signet broker performs automatic comparisons between contracts and specifications as soon as they are published.\nEach new contract undergoes comparison with all other specifications in the same integration, providing immediate feedback on backward compatibility.\nIn contrast, without a dedicated broker, developers must manually compare documents or write custom scripts for automation.","webhooks#Webhooks":"The Signet broker offers webhooks that integrate into the CI/CD pipeline. For instance, developers can use Signet webhooks to trigger a provider build whenever a new specification is published.\nWhile Github also provides webhooks, setting them up for these events requires more involvement and effort.","data-visualization-and-querying#Data Visualization and Querying":"The Signet Broker provides both graph and table representations for data visualization and filtering.\nThis enables developers to swiftly identify service dependencies and find comparison results or documents for specific consumer or provider versions.\nIn contrast, using Github alone would necessitate relying on third-party software to achieve the same level of functionality.","the-negatives#The Negatives":"","lack-of-version-control-collaboration#Lack of Version Control Collaboration":"One drawback of using the Signet broker is the absence of version control collaboration.\nWith Github, teams can leverage Github's pull request system to collaboratively manage changes on contracts and specifications.\nBy treating documents as code, teams can enforce collaboration by requiring approval from other teams for pull requests.","management-and-maintenance#Management and Maintenance":"Many teams are already utilizing Github or some form of version control in their existing workflows.\nIntegrating the Signet broker introduces an additional component to their infrastructure, which requires maintenance.","cost#Cost":"Using the Signet broker introduces additional costs as teams would have to pay for hosting the Signet broker.","vendor-lock-in#Vendor Lock-in":"Using the Signet broker may introduce the risk of vendor lock-in.\nIf teams decide to transition to a different contract testing platform in the future, they would need to extract their data from the Signet broker, which could be time-consuming."}},"/":{"title":"Index","data":{"":"This is the main site index."}},"/case-study/signet_framework/usecase":{"title":"Signet Framework","data":{"":"As small companies experience growth, maintaining a scalable and reliable microservices architecture becomes crucial. Development teams working on interdependent microservices need a robust contract testing framework to ensure compatibility and effective collaboration. Signet, an open-source, self-hosted framework for spec-driven contract testing, addresses these challenges.","who-is-signet-for#Who is Signet for?":"Signet is designed for small companies experiencing growth and utilizing a microservices architecture. It addresses the needs of development teams that seek an efficient and standardized approach to contract testing. The framework is ideal for teams aiming for seamless collaboration, early issue identification, and a reliable testing process for their microservices.Adopting a spec-driven approach offers significant advantages. Spec-driven contract testing promotes parallel development, allowing multiple teams to work concurrently on different microservices. By ensuring that each service aligns with the expected specifications, this approach accelerates the overall development process, enabling companies to deliver new features and updates more efficiently. Furthermore, testing against well-defined contracts ensures APIs adhere to agreed specifications, leading to increased reliability and reduced production errors."}},"/quickstart":{"title":"Quickstart","data":{"":"Every page should start with a first-level heading. The one for this page is # Quickstart which gets rendered as above.\nMake liberal use of subheadings (## Foo). These show up on the \"On This Page\" nav section to the right."}},"/case-study/design_decisions/provider_verification":{"title":"Provider Verification","data":{"":"","trust-but-verify#Trust, but Verify":"Consider a situation where the published consumer contract and provider specification are compatible, but the provider did not implement all the requirements defined in their specification.\nIn such cases, Deploy Guard should issue a warning, signaling that the provider's implementation might not be entirely compatible with the consumer.\nHowever, how can Deploy Guard accurately assess whether the provider has faithfully implemented their specification?\nThe solution to this problem is a process that we refer to as provider verification.\nProvider verification occurs when the provider tests their implementation against the published provider specification.\nThe results of this verification are then integrated into Deploy Guard, adding an extra layer of confidence in the compatibility between consumer and provider.","two-step-process#Two Step Process":"There are two steps to provider verification:\nTesting the provider\nPublishing the test results to the Signet broker\n\nUpon analyzing this process, we realized that publishing the test results does not require knowledge of how the results were obtained.\nThis observation led us to explore the possibility of decoupling the second step from the first.\nEssentially, we would shift the responsibility of testing the provider to the developer, granting them the freedom to employ their preferred testing tools.\nOnce the testing is complete, they can publish the results using the Signet CLI.\nWhile involving developers in the provider verification process was initially attractive, it also introduces more complexity to contract testing.\nThe developer would need to take on the burden of ensuring that their tests accurately cover all the requirements of the latest specification.\nTherefore, we ultimately decided that Signet should handle both steps of the verification process.","approaches-to-verification#Approaches to Verification":"","black-box-testing#Black Box Testing":"Having decided to include provider testing, we then considered a few options on how to implement it.\nThe approach we settled on is centered around black box testing.\nBlack box testing is a testing technique in which the code and implementation details of the tested software are unexposed to the tester.\nWe achieved this by simulating a mock consumer that utilizes the OpenAPI Specification to send requests to the provider.\nThe mock consumer sends a request to the provider for each described request in the specification.\nIf all the provider responses satisfy the requirements of the specification, then the provider is verified.\nThe main benefit of this approach is that it's both language and platform agnostic, making it easy to support any testing or server framework.","generate-unit-tests-from-the-specification#Generate Unit Tests from the Specification":"We also considered a couple of other approaches.\nThe first was to to generate unit tests automatically from the OpenAPI Specification; the provider is verified if they pass the generated unit tests.\nThe main advantage of this approach is its convenience in a new codebase, as it automates the process of writing unit tests for the specification.\nHowever, the code-invasive nature of this approach entails a few downsides.\nFirst, integrating our feature with existing testing frameworks would be problematic, as it would require developing individual support for each framework.\nSecond, we would also need a way to ensure synchronization between unit tests and specifications, otherwise developers can modify the unit tests in a way that inaccurately tests the specification.\nConsidering these issues, we decided that providing support for this feature would be outside the current scope of Signet.","generate-openapi-specification-from-code#Generate OpenAPI Specification from Code":"A second approach that we considered involves generating an additional OpenAPI Specification directly from the provider code.\nWe could then compare the generated specification with the published one to ensure compatibility.\nThis approach is well-suited for an existing codebase, but the implementation would be complicated because tools for specification generation tend to be tightly coupled to server frameworks.\nAs such, this approach would also require implementing individual support for each framework, which we considered impractical."}},"/quickstart/embed_image":{"title":"Embed an Image","data":{"":"Store images in the assets folder and then embed them using normal markdown syntax.\n![](../../assets/example_diagram.png)\nRenders as:"}},"/quickstart/folders":{"title":"Folders and _meta.json","data":{"":"","display-names-and-ordering#Display Names and Ordering":"Each folder can have its own _meta.json. Use this file to set what name is displayed in the left nav menu for each file and the order in which the names appear.Example:\n{\n\"folders\": \"Folders and _meta.json\",\n\"embed_image\": \"Embed an Image\",\n\"mdx_with_react\": \"MDX with React\"\n}","folders-as-pages#Folders as Pages":"A folder can also be a clickable page in its own right; just add a .md file with the same name as the folder in the same directory that the folder is in.See the \"Quickstart\" page for an example of this setup."}},"/case-study/background/challenges_testing_microservices":{"title":"Challenges Testing Microservices","data":{"":"","automated-testing#Automated Testing":"Automated software tests are broadly grouped into three categories:\nUnit Tests - test individual components of a program.\nThe subject under test is a single function, a class, or some other unit of non-trivial programming logic.\nIntegration Tests - test that multiple logical components of the system function correctly together.\nEnd-to-End Tests (\"E2E\") - exercise full-system workflows as they would occur when triggered in production.\n\nEach of these categories has its place.\nIndustry best-practice for creating a well-balanced test suite is often depicted with a pyramid.(Pyramid image here)This arrangement illustrates the tradeoff between the usefulness of the tests and the practicality of running them.\nTests which are higher on the pyramid have a broader scope and provide more confidence that the system works correctly.\nHowever, their broader scope tends to mean they take longer to run and provide less information about the causes when a failure occurs.\nIn contrast, tests that are lower on the pyramid can be executed more quickly and provide better isolation of bugs. However these tests provide less confidence that the application works correctly as a whole.","testing-microservices#Testing Microservices":"Compared with monoliths, microservices have more to gain from tests which are higher on the pyramid. This is because API calls involve more complexity than in-memory method calls, and because different microservices are often built by different teams.Let's explore an example which illustrates why broadly-scoped tests are so important for microservices. In order to do that it will be helpful to think about services assuming the role of either a provider or a consumer.\nProvider - a service which exposes some functionality and/or data for other services to use.\nConsumer - a service which requires functionality and/or data from another service in order to fulfill its own requirements.\n\nWell-designed microservices are loosely-coupled and should be allowed to remain ignorant of the implementation details of other services. This means that the team responsible for building a provider service should not need to understand how consumer services are implemented. Without knowing how consumers are implemented, it can be difficult for a provider team to know what changes they can make to their API without breaking the consumers. (1, 4, 10)Integration and E2E tests are well-suited to catch this type of error by verifying that each of the services can communicate with each other correctly. Unfortunately, it is challenging to apply broadly scoped tests to microservices without compromising independent deployability, clear ownership, and rapid continuous delivery/continuous delivery (CI/CD) cycles. Let's examine why this is the case.","challenges-with-integration-testing#Challenges with integration testing":"Independent deployability requires that new versions of a service can be built, deployed, and released without requiring other teams to get involved for integration testing. If one team wants to test the integration between their service and another service, they may need help from the other team for a number of reasons:\nKnowing which version (or versions) of the other service are currently released.\nSetting up the other service's runtime environment, configuring the service, and starting it up in the correct way.\nSetting up and configuring and external dependencies that the other service requires in order to function (this might require getting additional teams involved as well).\n\nTo address this problem, integration tests can be replaced with service tests, where the external service is replaced with a test double. The test double receives requests from the service being tested, and sends back a canned response. This enables a team to test the integration of their service with another, without needing to spin up the other service.Service tests only work as long as the real provider's interface does not change. If the provider service changes, the test double needs to be updated as well. Ideally, there should be an automated way to validate that the test double is up to date with the real service it represents.","challenges-with-e2e-testing#Challenges with E2E testing":"The difficulties of testing microservices are even greater in the context of E2E testing. There are many reasons for this, but we will take a look at two in particular.E2E testing requires simulating production conditions as best as possible in a dedicated testing environment. This is incredibly challenging with a large number of microservices, because it requires one or more instances of every service in the application to be spun up in the testing environment. Not only is this expensive, it also becomes increasingly difficult to accomplish as the architecture grows.Implementing this in practice may actually require multiple testing environments so that different teams can conduct tests on new versions of their service at the same time.The second challenge is that E2E test suites take a long time to run. They usually consist of consecutive user interactions that make up a workflow, and they often need to be run synchronously to ensure repeatability and consistency of state across different test runs. E2E tests are especially slow for microservices because services interact through network calls, which are orders of magnitude slower than reading from memory.\"I have seen [E2E tests] take up to a day to run, if not longer, and on one project I worked on, a full regression suite took six weeks!\" Sam Newman (Building Microservices - pg. 289)Slow E2E test suites decrease the speed at which new features can be shipped because they slow down the developer feedback loop. If it takes longer for developers to become aware that their changes broke something, it takes longer for them to fix it, and start the CI/CD process over again.In order to effectively test microservices, we need ways to increase our confidence that the application works correctly as a whole, without compromising the key benefits that lead us to adopting microservices in the first place. In practice, what this means is that we want to reduce the number of integration and E2E tests in our CI/CD pipeline, and replace them with faster, cheaper, and more maintainable forms of testing that catch the same kinds of bugs that are covered by our broadly-scoped tests. Contract testing is one alternative testing methodology that supports this goal."}},"/case-study/background/monoliths_and_microservices":{"title":"Testing Microservice Architectures","data":{"":"[This version flows (microservices -> testing -> testing microservices)]\n[This version goes much deeper into the differences between monoliths and microservices]We built the Signet framework to address a specific set of challenges with testing applications composed of microservices.\nBefore exploring those challenges, it may be helpful to set some context for what a microservice architecture is, so that we can more clearly explore why they are challenging to test.\nUnderstanding the characteristics of microservices, particularly when compared to monolithic applications, is key to understanding the trade-offs in the design of Signet.","what-is-a-monolith#What is a Monolith?":"In a monolithic architecture, all of the application's business logic is deployed together as a single unit.\nTypically this means that the code responsible for different business domains is stored in the same repository and is run as a single operating system process.\nWhen one piece of domain logic needs to access the functionality of another, it imports the programming construct for that domain (namespace, class, etc.), and interacts with it through in-memory method calls.","advantages-of-monoliths#Advantages of Monoliths":"A monolithic architecture is a great choice for many applications.\nIts characteristics make it especially well-suited for small to medium-sized applications managed by a single team.A key benefit of monoliths is that they enable a high degree of evolvability for modestly sized applications.\nEvolvability refers to how easy it is to update the application to address new use cases as business requirements change.\nWell-designed monoliths can be highly evolvable because each business domain is modelled by a programming construct (function, class, or module) rather than a distinct piece of infrastructure.\nAs the needs of a business change, is easier to re-architect programming constructs than it is to re-design infrastructure.Running all of the business logic in the same process also makes it easier to develop features that cut across business domains.\nThe functionality (or programming construct?) for each domain is available in memory, and can be easily imported and invoked as needed.\nThis also means that engineers only need to work with a single tech stack, which can reduce the cognitive load involved in development.Finally, deploying a monolith requires less operational overhead than deploying applications with multiple deployable units.\nThis frees up engineers to focus more effort on developing business logic instead of managing complex deployments.","monolithic-challenges#Monolithic Challenges":"Monoliths are not without their drawbacks, chiefly that they become more challenging to work with as the codebase and number of engineers grow in size.\nWorking on a large monolith requires an engineer to be knowledgeable about a large amount of code and to keep this knowledge in their head as they make changes.\nIt is easy to change something that unintentionally breaks other parts of the codebase.If there are many engineers working on the same codebase, making changes can also require a significant amount of coordination.\nIf one person makes a change that affects another person's code, or two people update the same code in different ways, they must work together to resolve the conflicts before their changes can be integrated and deployed.When the application consists of a single deployable unit, even deploying small changes becomes a high-risk activity.\nThis incentivizes teams to batch together multiple updates in every new deployment -- decreasing the rate at which features can be shipped, and increasing the risk that critical bugs are released into production.Although there are many examples of large organizations that employ a monolithic architecture, the characteristics of monoliths are better suited for smaller applications managed by a single team.\nFortunately, other architecture exist that offer a different set of trade-offs specifically tailored to operating at a large scale.","introducing-microservices#Introducing Microservices":"Another popular architecture, microservices, are specifically designed to meet the needs of large and/or highly scalable applications.\nIn a microservice architecture, the business logic is split up into independently deployable services, each of which represents a separate business domain.\nA service can be thought of as a miniature application which encapsulates its own business logic and data.\nA service exposes an interface so that other services can consume its functionality through messages sent over the network.","microservices-advantages#Microservices Advantages":"The fact that each microservice models an individual business domain provides numerous advantages for large or fast-scaling applications, the most significant of which deserve mention.First, microservices make it easy for teams to clearly identify the parts of the application they are responsible for.\nEach team only needs to concern themselves with the implementation details of their own service(s).\nIn many cases, this allows a team to own the full life-cycle of a service, from development, to testing and deployment, to post-deployment monitoring.Second, since each service can be deployed on its own infrastructure with its own runtime environment, services can be implemented in whatever way is most suitable for their business requirements.\nServices can use different tech stacks according to the trade-offs they offer, and can be scaled independently according to load and performance requirements of their role.\n[NTD by Zach: maybe cut this para for signet specificity?][NTD: maybe move this up if it is most important, assuming it did not require the prior stuff to set it up]\nIndependent deployability may be the most important benefit of a microservices architecture.\nWhen one part of a business needs a new feature, the team responsible for that domain should be able to build the feature, and deploy a new version of their service, without coordinating with any other teams.\nAs long as a service does not change its external interface in a backwards-incompatible way, it can be built and deployed independently.\nThis allows an organization to ship new features quickly even as the size of the application grows.","microservices-challenges#Microservices Challenges":"Microservies are intended to address the needs of applications that need to scale quickly and to a large size.\nThey are less suitable for small applications, especially when a business is new and requirements are not known with a high degree of confidence.For a single team that is responsible for managing the entire application, microservices add unnecessary complexity.\nHaving multiple units of deployment requires additional infrastructure and more coordination to release broadly-scoped features.\nIn addition, requiring different domains of business logic to interact through network calls instead of in-memory method calls introduces unreliability and latency.For newer businesses with unstable requirements, microservices decrease the potential evolvability of the app when compared to a monolithic architecture.\nIt may be challenging to predict with confidence what the business domains will be before the business is well established.\nMicroservices provide significant evolvability for individual business domains, but re-architecting [NTD: this may be too far...] the entire application can be much more difficult compared to a monolith.","testing-microservices#Testing Microservices":"The benefits of microservices are tailored to large applications with many engineers, or medium sized applications which require high scalability and evolvability.\nSimply having this architecture does not guarantee that these benefits will be realized, however.\nCare must also be taken to ensure that independent deployability and clear ownership are maintained through the development life cycle.\nTesting is an area that can be especially troublesome, and requires adaptation from the traditional strategies for testing monoliths.DDIA pg. 47."}},"/quickstart/style_guide":{"title":"Style Guide","data":{"":"Place each sentence on its own line.\nConsecutive non-blank lines will be rendered as normal paragraphs.\n\n\nThis is a serial/Oxford comma house.\n\"Eats, shoots ,  and leaves\".\nCf. these guys => catchy, but they are clearly wrong.\n\n\nFootnote format\nLet's standardize the capitalization of our terms:\nOpenAPI Specification\nDeploy Guard\nSignet broker (should we capitalize broker?)\n\n\n\nFootnote text."}},"/quickstart/mdx_with_react":{"title":"MDX with React","data":{"":"Using .mdx files instead of vanilla markdown lets you embed JSX:\nlet a = 1;\n\nconsole.log(a);","component#Component":"","external-component#External Component":""}}}