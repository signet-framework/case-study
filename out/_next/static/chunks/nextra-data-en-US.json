{"/about":{"title":"About","data":{"":"This is the about page! This page is shown on the navbar."}},"/case-study":{"title":"Case Study","data":{"":"The case study intro goes here."}},"/case-study/background/monoliths_and_microservices":{"title":"Of Monoliths and Microservices","data":{"":"Signet addresses specific challenges with testing applications composed of microservices.\nBefore exploring those challenges, we discuss the attributes of microservices which underpin the decisions we made when designing Signet.","what-is-a-monolith#What is a Monolith?":"Microservices are best introduced in contrast to monoliths.\nIn a monolithic architecture, all of the application's business logic is deployed together as a single unit.Typically, this means that each business domain is modeled by one or more programming constructs (e.g. class or module) that are stored in a shared repository.\nWhen deployed, the application runs as a single process, allowing business domains to interact with each other through in-memory method calls.","what-are-microservices#What are Microservices?":"In a microservice architecture, the business logic is split up into independently deployable services. Each service represents a single business domain.A service can be thought of as a miniature application which encapsulates its own business logic and data.\nA service exposes an interface so that other services can consume its functionality through messages sent over the network.","benefits-of-microservices#Benefits of Microservices":"Well-designed microservices enable high scalability, while also allowing teams to ship new features quickly.A key characteristic of a well-designed microservice architecture is independent deployability of its services.\nIndependent deployability means that teams can develop and release their services with minimal involvement from other teams.\nServices can thus evolve independently, as long as their API's remain backwards-compatible.\nThis allows an organization to ship new features quickly even as the size of the application grows.Microservices also promote clear boundaries of ownership.\nEach team of engineers is responsible for one or more microservices and only need to know how their own services are implemented.\nThis gives teams a narrow scope, allowing them to own the full life-cycle of their services, from development, to testing and deployment, to post-deployment monitoring.","testing-microservices#Testing Microservices":"In order to realize the benefits of microservices, care must be taken to ensure that independent deployability and clear ownership are maintained throughout the development life cycle.\nThese characteristics are challenging to maintain when testing that multiple microservices work correctly together.\nAs such, testing microservices requires adaptation from the traditional strategies for testing monoliths."}},"/case-study/contract_testing":{"title":"Contract Testing","data":{"":"Given two services that interact with each other, a contract test interrogates each service in isolation to see if the two interfaces are compatible with each other.\nThe test relies on a document known as a contract that formally describes the interactions between the services.Both services are individually tested to ensure that they conform to the contract.\nThe test fails if either service does not conform, indicating that the two services will not integrate correctly.TODO: diagram here illustrating an integration testTODO: diagram here illustrating a contract testQ: should these be one side-by-side diagram?","benefits-of-contract-testing#Benefits of Contract Testing":"Contract tests relieve the burden of having to deploy multiple services together for integration testing.\nThey build confidence that the services will work correctly together, without requiring both teams to coordinate their testing or know how to run the other team's service.Not only that, but they also provide much faster feedback than integration and E2E tests.\nContract tests behave more like unit test or service tests, and can be run quickly, cheaply, and early on in the CI/CD pipeline.\nIn fact, they are lightweight enough that a developer could even run them locally before initiating the build processes.An added benefit of contract tests is that they isolate bugs with more specificity than most integration and E2E tests.\nBecause each interaction (e.g. an HTTP request and response pair) is enumerated in the contract, a failing test can report exactly which messages are missing or malformed.","drawbacks-of-contract-testing#Drawbacks of Contract Testing":"While contract tests reduce the need for broadly-scoped tests, they do not replace them entirely.\nE2E tests provide a high degree of confidence because they try to mimic production conditions to the greatest extent possible.\nContract tests have a more narrow focus--to test the compatibility of interfaces and catch breaking changes quickly.\nContract tests do not replicate production conditions such as latency, service unavailability, and high amounts of load.Instead, contract tests reduce the quantity of broadly-scoped tests that an application needs. Ideally, these tests can even be moved out of the CI/CD pipeline, and run in a periodic manner that is decoupled from the deployment life-cycle of any given team.Another trade-off to consider is that implementing contract testing may require writing many new tests. Until there is sufficient coverage of a service's interface, that team cannot be confident that accidental breakages will be caught.","evaluating-various-forms-of-contract-testing#Evaluating various forms of Contract Testing":"There are many approaches to contract testing, and each vendor has a slightly different take on how it should be conducted. Methodologies are grouped into three categories according on how they determine the details of the contract. We will examine each of them in turn.\nConsumer-driven - the consumer service is the source of truth\nProvider-driven - the provider service is the source of truth\nSpec-driven - the source of truth is independent of either service's implementation","consumer-driven#Consumer-driven":"In consumer-driven contract testing, the consumer service is implemented first.\nAfter the consumer team has implemented their side of the integration, they use unit tests to generate a consumer contract, which describes the expectations that the consumer service has of the provider service.\nThe consumer contract is then handed over to the provider team and they implement the provider's API to satisfy the needs of the consumer.\nAfter the provider API is implemented, the requests in the contract are replayed against the API (a processed known as provider verification) and the responses are compared with those specified in the contract. If the provider service sends the correct response for each request, the test passes.A significant advantage of the consumer-driven approach is that the contract describes exactly which parts of the provider API is being used by the consumer.\nThis gives the provider team insight into how they can evolve their API without breaking any consumers.On the other hand, the consumer-driven approach has a critical drawback. It undermines independent deployability for consumer services.\nAfter generating the consumer contract, the consumer team must wait for the provider team to pull down the contract, spin up their service, and verify that it correctly implements the consumer's requirements.\nOnly if the provider passes verification can the consumer team proceed to deploying their service.\nIn the event that provider verification fails, either the consumer team must fix the issue and start the process over again, or they must wait for the provider team to update their API to satisfy the contract.In either case, the provider team must be involved any time the consumer team wants to deploy a new version of their service.\nTaking into account that microservices may have multiple external dependencies, consumer-driven contract testing requires significant cross-team coordination--placing a severe limitation on how quickly new software can be deployed.","provider-driven#Provider-driven":"Provider-driven contract testing is nearly the reverse of consumer-driven.\nThe provider service is implemented first, and a provider contract is generated that describes the provider's side of the integration.\nUsually the provider contract comes in the form of an API specification, other times the provider team distributes a test double which consumers can test against.The main benefit of a provider-driven approach is that it gives the provider team authority over what the integration looks like.\nWhether or not this makes sense depends on the organization and the roles of the services involved.\nOne situation where this is appropriate is when the provider has a large number of consumers, and it is impractical for the provider team to negotiate their API will all of them at once.In a provider-driven model, it is less clear whether contract testing will give the provider team insight into how their API is being consumed. The contract describes what the provider offers, not necessarily how consumers are using it. Provider-driven solutions commonly support the ability for writing consumer-specific test cases in the provider contract, but this demands substantial additional effort.","spec-driven#Spec-driven":"Spec-driven contract testing occurs when the API spec is defined separately from either service's implementation.\nUsually this means that the consumer and provider teams agree on the API spec ahead of time, before either service has implemented it.This approach flows naturally out of \"Spec-first\" API design, a practice where the provider team decides on a spec before writing the code, instead of documenting their implementation after it is completed.\nThis design philosophy is beneficial because it allows both the consumer and provider services to be implemented simultaneously.\nAs each service finishes implementation, it can be independently tested against the API spec to verify that it will integrate correctly with the other service.Spec-driven contract testing is the most conducive to independent deployability.\nThe API spec is decided at the beginning, and both services can be tested against the spec independently.\nNeither team needs help from the other to test the integration.\nAs long as the both teams require every new version of their service to be tested for conformance to the spec, the deployment cycles of the two services can remain decoupled.","existing-solutions#Existing Solutions":"","pact#Pact":"Pact is the most well-known open-source option for contract testing.\nIt uses a purely consumer-driven model.Two notable characteristics of Pact are that it relies on client libraries for writing consumer contract tests, and it includes a backend application called a \"broker.\"\nThe broker is responsible for managing contracts and describing the reasons for failed tests.\nIt also gives developers insight into which services are deployed where, and whether or not their service is safe to be deployed to a given environment.We see two main challenges with Pact. The fact that it only works with a consumer-driven approach means that it does not maximize independent deployability. It also requires substantial investment in writing new unit tests.","pactflow#PactFlow":"The original creators of Pact have more recently come out with a paid Software-as-a-Service (SaaS) product called PactFlow.\nPactFlow builds on the foundation of Pact to provided a service they call \"bidirectional\" contract testing.\nBidirectional supports both spec-driven and provider-driven models by allowing the provider's API spec to be published before or after it has been tested against the provider service.While PactFlow significantly improves upon the flexibility of Pact, it still requires substantial effort to add contract testing into the CI/CD workflow.\nConsumer teams still need to write new unit tests using a Pact client library, or else configure a third-party tool for generating the consumer contract.\nProvider teams likewise need to supply their own solution for testing the provider implementation against the API spec.","karate#Karate":"Karate is another popular open-source solution for contract testing.\nKarate takes a unique approach to the provider-driven model.\nRather than creating an API spec, the provider team uses Karate to generate a mock of the provider service.\nThe consumer team can then use the mock in their service tests to verify that the consumer will integrate correctly with the real provider.\nAlthough Karate does not use unit tests to generate a consumer contract, developer's still use Karate's DSL to manually program the provider mock to respond correctly to the specific requests from the consumer.","specmatic#Specmatic":"Specmatic is an open-source offering for spec-driven contract testing.\nA key feature of Specmatic is that it offers a way to generate the contract by automatically recording the interactions between the consumer and provider service.\nThis means that contract testing can be achieved with a significantly smaller startup cost--there is no need to write new unit tests to get up and running.Another characteristic of Specmatic is that it does not use a broker--contracts are stored in version control instead.\nWhile this comprises a simple solution for managing contracts, it loses out on some useful features that a broker can provide.\nFor instance, in order for a CI/CD pipeline to automatically gate a deployment based on what is currently deployed, significant effort must be expended to DIY this capability."}},"/case-study/design_decisions/contract_generation":{"title":"Contract Generation","data":{"":"At their core, consumer contracts and provider specifications are JSON or YAML files that adhere to a specific schema, which allows them to be written using a text editor.\nHowever, relying on this manual approach introduces the risk of misalignment between the actual service and its corresponding document.\nWhile we have successfully addressed this problem for the provider side through provider verification, we now need to tackle the same challenge for the consumer side.","replicate-the-provider-approach#Replicate the Provider Approach":"One option we considered is to replicate the approach used for the provider side.\nEssentially, we'll shift the responsibility of writing the contract onto the developer and offer consumer verification as a Signet feature.\nHowever, we quickly realized that there is no practical benefit to writing a Pact file by hand.\nIn contrast, for OpenAPI Specifications, designing and writing the specification by hand allows for collaboration, a key component of spec-driven development.\nAs collaboration is not beneficial for consumer contracts, we decided that automating the consumer contract generation is more productive for the developer.","generate-consumer-contract#Generate Consumer Contract":"Before considering any implementations of this approach, we assumed that teams are already performing consumer service tests that involve sending HTTP requests to a mock provider.\nIn other words, their testing infrastructure has already configured a mocking service.\nFurthermore, their mocking service configuration contains descriptions of the expected HTTP requests and responses between the consumer and provider.\nAssuming this scenario, Signet can extract information from the configured mocking service to generate the consumer contract.\nWe considered two extraction methods, which we refer to as recording and reading, and although both can coexist, we decided only to implement recording.","recording#Recording":"This approach involves setting up a passthrough proxy between the consumer and mock provider server to record all HTTP requests and responses during the service tests.\nAfter the tests execute, we can use the recorded data to generate a consumer contract.\nThe benefit of this approach is that it is not code-invasive and is compatible with any HTTP mocking service, allowing easy integration into an existing codebase.","reading#Reading":"This approach involves reading the mock service configuration files to extract the expected HTTP requests and responses.\nWe can then use the extracted data to create the consumer contract.\nOne advantage of this approach is that a proxy would no longer be necessary, requiring one less component.\nAlso, since there is no recording, we can generate the consumer contract without executing the service tests.\nThe main disadvantage is that the format of the HTTP request and response definitions would differ depending on the mocking service, requiring us to implement individual support for each service. As such, we decided that this approach was out of our current scope."}},"/case-study/design_decisions/central_document_repository":{"title":"Central Document Repository","data":{"":"","single-source-of-truth#Single Source of Truth":"A crucial characteristic of Deploy Guard is its global consistency, ensuring that running Deploy Guard for the consumer team yields the same results as if the provider team were running it.\n[NTD: This reads as running deploy guard for either participant of an integration should yield the same result. But I don't think that is right because then the provider would never be able to deploy. Chicken and egg kinda thing.]\nWithout global consistency, teams must face the challenge of resolving conflicts in Deploy Guard results.Deploy Guard's results depend on the definitions of both the consumer contract and the provider specification.\nConsequently, global consistency can only be achieved if Deploy Guard reads the documents from a central repository.\nReading documents from individual repositories of the consumer and provider teams introduces the risk of unsynchronized documents, leading to conflicting results in Deploy Guard.\nWhile Github can serve as a central repository, we decided that developing a dedicated broker would be a more suitable approach as it allows us to provide features specific to contract testing. We'll discuss the tradeoffs of this decision in the following sections.","the-positives#The Positives":"","encapsulating-logic#Encapsulating Logic":"With a dedicated broker, Signet's functionality is no longer confined within the Signet CLI.\nInstead, the broker handles various tasks, including the logic for Deploy Guard.\nThis enables automatic fetching of data for documents and deployment states of consumer and provider versions.\nIf Github were the central repository, implementing automatic fetching would be challenging, and developers would have to manually provide Deploy Guard with data about documents and deployment states.","automatic-comparison#Automatic Comparison":"The Signet broker performs automatic comparisons between contracts and specifications as soon as they are published.\nEach new contract undergoes comparison with all other specifications in the same integration, providing immediate feedback on backward compatibility.\nIn contrast, without a dedicated broker, developers must manually compare documents or write custom scripts for automation.","webhooks#Webhooks":"The Signet broker offers webhooks that integrate into the CI/CD pipeline. For instance, developers can use Signet webhooks to trigger a provider build whenever a new specification is published.\nWhile Github also provides webhooks, setting them up for these events requires more involvement and effort.","data-visualization-and-querying#Data Visualization and Querying":"The Signet Broker provides both graph and table representations for data visualization and filtering.\nThis enables developers to swiftly identify service dependencies and find comparison results or documents for specific consumer or provider versions.\nIn contrast, using Github alone would necessitate relying on third-party software to achieve the same level of functionality.","the-negatives#The Negatives":"","lack-of-version-control-collaboration#Lack of Version Control Collaboration":"One drawback of using the Signet broker is the absence of version control collaboration.\nWith Github, teams can leverage Github's pull request system to collaboratively manage changes on contracts and specifications.\nBy treating documents as code, teams can enforce collaboration by requiring approval from other teams for pull requests.","management-and-maintenance#Management and Maintenance":"Many teams are already utilizing Github or some form of version control in their existing workflows.\nIntegrating the Signet broker introduces an additional component to their infrastructure, which requires maintenance.","cost#Cost":"Using the Signet broker introduces additional costs as teams would have to pay for hosting the Signet broker.","vendor-lock-in#Vendor Lock-in":"Using the Signet broker may introduce the risk of vendor lock-in.\nIf teams decide to transition to a different contract testing platform in the future, they would need to extract their data from the Signet broker, which could be time-consuming."}},"/":{"title":"Index","data":{"":""}},"/case-study/signet_framework/usecase":{"title":"Signet Framework","data":{"":"As small companies experience growth, maintaining a scalable and reliable microservices architecture becomes crucial. Development teams working on interdependent microservices need a robust contract testing framework to ensure compatibility and effective collaboration. Signet, an open-source, self-hosted framework for spec-driven contract testing, addresses these challenges.","who-is-signet-for#Who is Signet for?":"Signet is designed for small companies experiencing growth and utilizing a microservices architecture. It addresses the needs of development teams that seek an efficient and standardized approach to contract testing. The framework is ideal for teams aiming for seamless collaboration, early issue identification, and a reliable testing process for their microservices.Adopting a spec-driven approach offers significant advantages. Spec-driven contract testing promotes parallel development, allowing multiple teams to work concurrently on different microservices. By ensuring that each service aligns with the expected specifications, this approach accelerates the overall development process, enabling companies to deliver new features and updates more efficiently. Furthermore, testing against well-defined contracts ensures APIs adhere to agreed specifications, leading to increased reliability and reduced production errors."}},"/case-study/design_decisions/provider_verification":{"title":"Provider Verification","data":{"":"","trust-but-verify#Trust, but Verify":"Consider a situation where the published consumer contract and provider specification are compatible, but the provider did not implement all the requirements defined in their specification.\nIn such cases, Deploy Guard should issue a warning, signaling that the provider's implementation might not be entirely compatible with the consumer.\nHowever, how can Deploy Guard accurately assess whether the provider has faithfully implemented their specification?\nThe solution to this problem is a process that we refer to as provider verification.Provider verification occurs when the provider tests their implementation against the published provider specification.\nThe results of this verification are then integrated into Deploy Guard, adding an extra layer of confidence in the compatibility between consumer and provider.","two-step-process#Two Step Process":"There are two steps to provider verification:\nTesting the provider\nPublishing the test results to the Signet broker\n\nUpon analyzing this process, we realized that publishing the test results does not require knowledge of how the results were obtained.\nThis observation led us to explore the possibility of decoupling the second step from the first.\nEssentially, we would shift the responsibility of testing the provider to the developer, granting them the freedom to employ their preferred testing tools.\nOnce the testing is complete, they can publish the results using the Signet CLI.While involving developers in the provider verification process was initially attractive, it also introduces more complexity to contract testing.\nThe developer would need to take on the burden of ensuring that their tests accurately cover all the requirements of the latest specification.\nTherefore, we ultimately decided that Signet should handle both steps of the verification process.","approaches-to-verification#Approaches to Verification":"Having decided to include provider testing, we then considered a few options on how to implement it.\nThe approach we settled on is centered around black box testing.","black-box-testing#Black Box Testing":"Black box testing is a testing technique in which the code and implementation details of the tested software are unexposed to the tester.\nWe achieved this by simulating a mock consumer that utilizes the OpenAPI Specification to send requests to the provider.\nThe mock consumer sends a request to the provider for each described request in the specification.\nIf all the provider responses satisfy the requirements of the specification, then the provider is verified.The main benefit of this approach is that it is both language and platform agnostic, making it easy to support any testing or server framework.","alternatives#Alternatives":"During our design phase we also considered a couple of alternative approaches to provider verification.","generate-unit-tests-from-the-specification#Generate Unit Tests from the Specification":"The first was to to generate unit tests automatically from the OpenAPI Specification; the provider is verified if they pass the generated unit tests.\nThe main advantage of this approach is its convenience in a new codebase, as it automates the process of writing unit tests for the specification.However, the code-invasive nature of this approach entails a few downsides.\nFirst, integrating our feature with existing testing frameworks would be problematic, as it would require developing individual support for each framework.\nSecond, we would also need a way to ensure synchronization between unit tests and specifications, otherwise developers can modify the unit tests in a way that inaccurately tests the specification.Considering these issues, we decided that providing support for this feature would be outside the current scope of Signet.","generate-openapi-specification-from-code#Generate OpenAPI Specification from Code":"A second approach that we considered involves generating an additional OpenAPI Specification directly from the provider code.\nWe could then compare the generated specification with the published one to ensure compatibility.While this approach is well-suited for an existing codebase, the implementation would be complicated because tools for specification generation tend to be tightly coupled to server frameworks.\nAs such, this approach would also require implementing individual support for each framework, which we considered impractical."}},"/quickstart":{"title":"Quickstart","data":{"":"Every page should start with a first-level heading. The one for this page is # Quickstart which gets rendered as above.\nMake liberal use of subheadings (## Foo). These show up on the \"On This Page\" nav section to the right."}},"/quickstart/embed_image":{"title":"Embed an Image","data":{"":"Store images in the assets folder and then embed them using normal markdown syntax.\n![](../../assets/example_diagram.png)\nRenders as:"}},"/quickstart/folders":{"title":"Folders and _meta.json","data":{"":"","display-names-and-ordering#Display Names and Ordering":"Each folder can have its own _meta.json. Use this file to set what name is displayed in the left nav menu for each file and the order in which the names appear.Example:\n{\n\"folders\": \"Folders and _meta.json\",\n\"embed_image\": \"Embed an Image\",\n\"mdx_with_react\": \"MDX with React\"\n}","folders-as-pages#Folders as Pages":"A folder can also be a clickable page in its own right; just add a .md file with the same name as the folder in the same directory that the folder is in.See the \"Quickstart\" page for an example of this setup."}},"/quickstart/style_guide":{"title":"Style Guide","data":{"":"Place each sentence on its own line.\nConsecutive non-blank lines will be rendered as normal paragraphs.\n\n\nThis is a serial/Oxford comma house.\n\"Eats, shoots ,  and leaves\".\nCf. these guys => catchy, but they are clearly wrong.\n\n\nFootnote format\nUse this syntax to mark the footnote inline with the text:\nSome words.[^1] More words.\n\nThen at the bottom of the file:\n[^1]: This is footnote text.\n\n\n\nLet's standardize the capitalization of our terms:\nOpenAPI Specification\nDeploy Guard\nSignet broker (should we capitalize broker?)\n\n\n\nThis is footnote text."}},"/case-study/background/challenges_testing_microservices":{"title":"Challenges Testing Microservices","data":{"":"","automated-testing#Automated Testing":"Automated software tests are broadly grouped into three categories:\nUnit Tests - test individual components of a program.\nThe subject under test is a single function, class, or some other unit of non-trivial programming logic.\nIntegration Tests - test that multiple logical components of the system function correctly together.\nEnd-to-End Tests (E2E) - exercise full-system workflows as they would occur when triggered in production.\n\nEach type of test serves a unique purpose and has a place in a well-balanced test suite.\nA pyramid is often used to illustrate how each type of test relates to the others.TODO: This is a placeholder:\n\nTests which are higher on the pyramid have a broader scope and provide more confidence that the system works correctly.\nHowever, broadly-scoped tests take longer to run, and do less to pinpoint the exact cause of a failure.In contrast, tests that are lower on the pyramid execute more quickly and provide better isolation of bugs.\nHowever, these tests provide less confidence that the application works correctly as a whole.","testing-microservices#Testing Microservices":"Compared with monoliths, microservices have more to gain from tests that are high on the pyramid.\nThis is because API calls over the network are more complex and significantly less reliable than in-memory method calls.\nAn additional factor is that different microservices may be built by different teams.\nBroadly-scoped tests confirm that multiple teams understand each other correctly.Let us explore an example which illustrates why broadly-scoped tests are so important for microservices.\nIn order to do that it will be helpful to think about services assuming the role of either a provider or a consumer.\nProvider - a service which exposes some functionality and/or data for other services to use\nConsumer - a service which requires functionality and/or data from another service in order to fulfill its own requirements\n\nMicroservices should be loosely coupledâ€”one team should not need to know how another team's services are implemented.\nSuppose a provider team wants to change their service's API.\nIf the provider team does not know how the consumer services are implemented, it is easy for them to accidentally change the API in a way that breaks a consumer.Integration and E2E tests are well-suited to catch this type of error before it is introduced into production.\nHowever, applying broadly-scoped tests to microservices can hinder independent deployability, clear ownership, and rapid development cycles.\nIn the following section, we will explore why this is the case.","challenges-with-integration-testing#Challenges with Integration Testing":"Independent deployability requires that new versions of a service can be built, deployed, and released with minimal involvement from other teams.\nHowever, in order for one team to perform integration tests with another team's service, they may need help with a number of things:\nKnowing which version (or versions) of the other service are currently released\nSetting up the other service's runtime environment, configuring the service, and starting it up in the correct way\nSetting up and configuring the other service's external dependencies (this might require getting additional teams involved as well)\n\nTo address this problem, integration tests can be replaced with service tests, where the external service is replaced with a test double.\nThe test double receives requests from the service being tested and sends back a canned response.\nThis enables a team to test the integration of their service with another, without actually spinning up the other service.TODO: maybe diagramHowever, service tests only work as long as the real provider's interface does not change; if the provider service changes, the test double needs to be updated as well.\nIdeally, there should be an automated way to validate that the test double is up to date with the real service it represents.","challenges-with-e2e-testing#Challenges with E2E testing":"The difficulties of testing microservices are even greater in the context of E2E testing.\nThere are many reasons for this, but we will take a look at two in particular.First, E2E testing requires simulating production conditions as best as possible in a dedicated testing environment.\nThis is incredibly challenging with a large number of microservices, as it requires one or more instances of every service in the application to be spun up in the environment.\nNot only is this expensive, it also becomes increasingly difficult to accomplish as the architecture grows.In practice, E2E testing may require multiple testing environments so that different teams can conduct tests on new versions of their service at the same time.The second challenge is that E2E tests are slow.\nThey usually consist of consecutive user interactions and may execute synchronously to ensure repeatability and consistency of state across different test runs.\nE2E tests are especially slow for microservices because services interact through network calls, which are orders of magnitude slower than reading from memory.\n\"I have seen [E2E tests] take up to a day to run, if not longer, and on one project I worked on, a full regression suite took six weeks!\"\nSlow E2E test suites decrease the speed at which new features can be shipped because they slow down the developer feedback loop.\nIf it takes longer for developers to become aware that their changes broke something, it takes longer for them to fix it and start the CI/CD process over again.Thus, in order to effectively test microservices, we need ways to increase our confidence that the application works correctly as a whole, without compromising the key benefits that lead us to adopting microservices in the first place.","the-crux-of-the-matter#The crux of the matter":"As we have seen, there are a number of things to consider when testing microservices. We want to have confidence that our services work correctly together.\nBut in doing so, we do not want to compromise the benefits of this style of architecture.What we need are testing methodologies that catch the same bugs as integration and E2E tests, while maintaining a high degree of independent deployability and clear boundaries of ownership.\nThese tests should also be faster, cheaper, and more maintainable than broadly-scoped tests. Contract testing is one such alternative, and it is there that we will turn our attention next.Sam Newman (Building Microservices - pg. 289)"}},"/quickstart/mdx_with_react":{"title":"MDX with React","data":{"":"Using .mdx files instead of vanilla markdown lets you embed JSX:\nlet a = 1;\n\nconsole.log(a);","component#Component":"","external-component#External Component":""}}}